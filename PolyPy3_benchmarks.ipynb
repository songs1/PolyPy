{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "26143f4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv1D, Dropout, Flatten\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import ConstantKernel, RBF, WhiteKernel\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "\n",
    "BOLD = '\\033[1m'\n",
    "END = '\\033[0m'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e8f77dd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Support functions\n",
    "\n",
    "def train_test_split(X, y, test_idx=None, test_size=0.2):\n",
    "    ''' Split input data X and labels y into training and testing arrays '''\n",
    "    n_list = list(range(len(y)))\n",
    "    if test_idx is None:\n",
    "        print('\\n -- Performing NEW train-test split -- \\n')\n",
    "        test_idx = np.random.choice(n_list, replace=False, size=int(test_size*len(y)))\n",
    "    else:\n",
    "        test_idx = np.array(test_idx)\n",
    "    train_idx = np.array([i for i in n_list if i not in test_idx])\n",
    "    X_train = X[train_idx,:]\n",
    "    X_test = X[test_idx,:]\n",
    "    y_train = y[train_idx]\n",
    "    y_test = y[test_idx]\n",
    "    return X_train, y_train, X_test, y_test, test_idx\n",
    "\n",
    "\n",
    "def pred_vs_true(y_true, y_pred, plotTitle=None, plotColor='tab:blue', saveLoc=None,\n",
    "                 xLabel='Test Labels', yLabel='Predictions'):\n",
    "    ''' Plot an array of predicted values vs. label values\n",
    "        Return the correlation score (R^2), mean average error (MAE), and root mean squared error (RMSE)\n",
    "    '''\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    rmse = mean_squared_error(y_true, y_pred, squared=False)\n",
    "    if plotTitle:\n",
    "        plt.figure(figsize=(6,6))\n",
    "        plt.title(f'{plotTitle}\\nR^2: {round(r2,3)},   MAE: {round(mae,2)},   RMSE: {round(rmse,2)}', size=14)\n",
    "        plt.xlabel(xLabel, size=20)\n",
    "        plt.ylabel(yLabel, size=20)\n",
    "        plt.scatter(y_true, y_pred, c=plotColor)\n",
    "        ymin, ymax = min(y_true), max(y_true)\n",
    "        plt.plot([ymin, ymax], [ymin, ymax], c='k')\n",
    "        plt.grid()\n",
    "        if saveLoc: plt.savefig(f'{saveLoc}.png', facecolor='w', bbox_inches='tight')\n",
    "        plt.show()\n",
    "        plt.close()\n",
    "    return r2, mae, rmse\n",
    "\n",
    "    \n",
    "def compare_metrics(r2_vals, mae_vals, rmse_vals, plotTitle=None, plotColor='tab:blue', saveLoc=None):\n",
    "    plt.figure()\n",
    "    plt.title(plotTitle, size=14)\n",
    "    plt.xlabel('R^2', size=20)\n",
    "    plt.ylabel('Error', size=20)\n",
    "    plt.plot(r2_vals, mae_vals, 'D', c=plotColor, label='MAE', markerfacecolor='white')\n",
    "    plt.plot(r2_vals, rmse_vals, 'o', c=plotColor, label='RMSE')\n",
    "    plt.grid()\n",
    "    plt.legend(bbox_to_anchor=(1,1), loc='upper left', shadow=True, fontsize=16)\n",
    "    if saveLoc: plt.savefig(f'{saveLoc}.png', facecolor='w', bbox_inches='tight')\n",
    "    plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4653dba6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Method Implemented:\tTao_MLP  \t(keras)\n",
      "Method Implemented:\tmy_MLP  \t(keras)\n",
      "Method Implemented:\tTao_CNN_1D\t(keras)\n",
      "Method Implemented:\tTao_RF  \t(sklearn)\n"
     ]
    }
   ],
   "source": [
    "def Tao_MLP(X_train, y_train, epochs=100, verbose=0, out_dims=1):\n",
    "    model = Sequential([\n",
    "        Dense(8, activation='relu'),\n",
    "        Dense(8, activation='relu'),\n",
    "        Dense(out_dims)\n",
    "    ])\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "    model.fit(X_train, y_train, batch_size=32, epochs=epochs, verbose=verbose)\n",
    "    return model\n",
    "print('Method Implemented:\\tTao_MLP  \\t(keras)')\n",
    "\n",
    "\n",
    "def my_MLP(X_train, y_train, epochs=100, verbose=0):\n",
    "    model = Sequential([\n",
    "        Dense(32, activation='relu'),\n",
    "        Dense(32, activation='relu'),\n",
    "        Dense(32, activation='relu'),\n",
    "        Dense(1)\n",
    "    ])\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "    model.fit(X_train, y_train, batch_size=32, epochs=epochs, verbose=verbose)\n",
    "    return model\n",
    "print('Method Implemented:\\tmy_MLP  \\t(keras)')\n",
    "\n",
    "    \n",
    "def Tao_CNN_1D(X_train, y_train, epochs=100, verbose=0):\n",
    "    if len(X_train.shape) == 2:\n",
    "        X_train = np.expand_dims(X_train, axis=-1).astype(float)\n",
    "    model = Sequential([\n",
    "        Conv1D(filters=8, kernel_size=8, strides=1),\n",
    "        Dropout(0.1),\n",
    "        Flatten(),\n",
    "        Dense(1)\n",
    "    ])\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "    model.fit(X_train, y_train, epochs=100, verbose=verbose)\n",
    "    return model\n",
    "print('Method Implemented:\\tTao_CNN_1D\\t(keras)')\n",
    "\n",
    "\n",
    "def Tao_RF(X_train, y_train):\n",
    "    model = RandomForestRegressor(n_estimators=100, max_depth=10, min_samples_split=2)\n",
    "    model.fit(X_train, y_train)\n",
    "    return model\n",
    "print('Method Implemented:\\tTao_RF  \\t(sklearn)')\n",
    "\n",
    "\n",
    "\n",
    "def my_GPR(X_train, y_train, restarts=9):\n",
    "    kernel = 1 * RBF(length_scale=1.0, length_scale_bounds=(1e-2, 1e2))\n",
    "    model = GaussianProcessRegressor(kernel=kernel, n_restarts_optimizer=restarts)\n",
    "    model.fit(X_train, y_train)\n",
    "    return model\n",
    "print('Method Implemented:\\tmy_GPR  \\t(sklearn)')\n",
    "\n",
    "\n",
    "def Tao_GPR(X_train, y_train, restarts=9):\n",
    "    kernel = ConstantKernel(constant_value=1.0) * RBF(length_scale=10) * WhiteKernel(noise_level=0.1)\n",
    "    model = GaussianProcessRegressor(kernel=kernel, n_restarts_optimizer=restarts)\n",
    "    model.fit(X_train, y_train)\n",
    "    return model\n",
    "print('Method Implemented:\\tTao_GPR  \\t(sklearn)')\n",
    "\n",
    "None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "00b290f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Function Defined:\tmulti_test\n"
     ]
    }
   ],
   "source": [
    "def multi_test(model, X, y, test_indices=[None]*10, nTrials=20, saveFile=None, **model_kwargs):\n",
    "    \n",
    "    r2_results, mae_results, rmse_results = [], [], []\n",
    "    print(f'X.shape: {X.shape}')\n",
    "    \n",
    "    for test, test_idx in enumerate(test_indices):\n",
    "        print(f'{BOLD}[Test #{test}]:{END}', end=' [')\n",
    "        X_train, y_train, X_test, y_test, _ = train_test_split(X, y, test_idx)\n",
    "        if model == Tao_CNN_1D: X_test = np.expand_dims(X_test, axis=-1)\n",
    "        r2_test, mae_test, rmse_test, test_models = [], [], [], {}\n",
    "        \n",
    "        for trial in range(nTrials):\n",
    "            mod = model(X_train, y_train, **model_kwargs)\n",
    "            y_pred = mod.predict(X_test)\n",
    "            r2, mae, rmse = pred_vs_true(y_test, y_pred)\n",
    "            r2_test.append(r2)\n",
    "            mae_test.append(mae)\n",
    "            rmse_test.append(rmse)\n",
    "            print(f'{round(r2*100)}', end=',')\n",
    "                        \n",
    "        r2_results.append(r2_test)\n",
    "        mae_results.append(mae_test)\n",
    "        rmse_results.append(rmse_test)\n",
    "        print(f'] best R^2: {round(max(r2_test),3)}')\n",
    "    \n",
    "    print('done')\n",
    "    print('\\nAverage of Bests (+/- St.Dev.):')\n",
    "    best = np.max(r2_results, axis=-1)\n",
    "    r2_report = f'R^2:\\t{np.mean(best)}   +/-   {np.std(best)}'\n",
    "    print(r2_report)\n",
    "    best = np.min(mae_results, axis=-1)\n",
    "    mae_report = f'MAE:\\t{np.mean(best)}   +/-   {np.std(best)}'\n",
    "    print(mae_report)\n",
    "    best = np.min(rmse_results, axis=-1)\n",
    "    rmse_report = f'RMSE:\\t{np.mean(best)}   +/-   {np.std(best)}'\n",
    "    print(rmse_report)\n",
    "    \n",
    "    print('\\nGlobal Average (+/- St.Dev.):')\n",
    "    r2_global = f'R^2:\\t{np.mean(r2_results)}   +/-   {np.std(r2_results)}'\n",
    "    print(r2_global)\n",
    "    mae_global = f'MAE:\\t{np.mean(mae_results)}   +/-   {np.std(mae_results)}'\n",
    "    print(mae_global)\n",
    "    rmse_global = f'RMSE:\\t{np.mean(rmse_results)}   +/-   {np.std(rmse_results)}'\n",
    "    print(rmse_global)\n",
    "    \n",
    "    if saveFile:\n",
    "        if saveFile[-4:] != '.txt':\n",
    "            saveFile += '.txt'\n",
    "        with open(saveFile, 'w') as file:\n",
    "            file.write(f'Model:\\t{str(model).split(\" \")[1]}\\n')\n",
    "            file.write(f'X.shape:\\t{X.shape}\\n')\n",
    "            file.write(f'nTests:\\t{len(test_indices)}\\n')\n",
    "            file.write(f'nTrials:\\t{nTrials}\\n')\n",
    "            \n",
    "            file.write(f'\\nAverage of Bests (+/- St.Dev.):\\n')\n",
    "            file.write(f'{r2_report}\\n')\n",
    "            file.write(f'{mae_report}\\n')\n",
    "            file.write(f'{rmse_report}\\n')\n",
    "            \n",
    "            file.write(f'\\nGlobal Average (+/- St.Dev.):\\n')\n",
    "            file.write(f'{r2_global}\\n')\n",
    "            file.write(f'{mae_global}\\n')\n",
    "            file.write(f'{rmse_global}\\n')\n",
    "            \n",
    "            file.write(f'\\nR^2:\\n{r2_results}\\n')\n",
    "            file.write(f'\\nMAE:\\n{mae_results}\\n')\n",
    "            file.write(f'\\nRMSE:\\n{rmse_results}\\n')\n",
    "            \n",
    "    return r2_results, mae_results, rmse_results\n",
    "\n",
    "print('\\nFunction Defined:\\tmulti_test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8880efba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Function Defined:\tbenchmark\n"
     ]
    }
   ],
   "source": [
    "def benchmark(model, smiles, X, y, test_idx, prefix='No info\\n', nTrials=20, saveFile=None, **model_kwargs):\n",
    "    \n",
    "    # opt, metric = best_metric # just do highest r^2 for now\n",
    "    X_train, y_train, X_test, y_test, _ = train_test_split(X, y, test_idx)\n",
    "    results = [] # list of dicts\n",
    "    \n",
    "    print('Start Trials:',end=' ')\n",
    "    for trial in range(nTrials):\n",
    "        mod = model(X_train, y_train, **model_kwargs)\n",
    "        y_pred = mod.predict(X_test)\n",
    "        r2, mae, rmse = pred_vs_true(y_test, y_pred)\n",
    "        results.append({'r2':r2, 'model':mod})\n",
    "        print(round(r2*100), end=' ') \n",
    "    \n",
    "    results.sort(key=lambda res: res['r2'], reverse=True)\n",
    "    print(f'\\nBest Test R^2: {results[0][\"r2\"]}')\n",
    "    \n",
    "    mod = results[0]['model']\n",
    "    y_pred = mod.predict(X)\n",
    "\n",
    "    if saveFile:\n",
    "        if saveFile[-4:] != '.txt':\n",
    "            saveFile += '.txt'\n",
    "        with open(saveFile, 'w') as file:\n",
    "            file.write(f'SMILES,Predicted Value,Used in Training,Target Value ({prefix})\\n')\n",
    "            for i, (sm, y_true_val, y_pred_val) in enumerate(zip(smiles, y, y_pred)):\n",
    "                train_included = 0 if i in test_idx else 1\n",
    "                yt = float(y_pred_val)\n",
    "                file.write(f'{sm},{round(yt,5)},{train_included},{round(y_true_val,5)}\\n')\n",
    "            \n",
    "    return results\n",
    "print('Function Defined:\\tbenchmark')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a178bd0e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
